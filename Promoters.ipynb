{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUMA: Promoter Unraveling through Machine-learning Algorithms\n",
    "<img src=\"https://raw.githubusercontent.com/CarolusVitalis/PUMA/main/Images/PUMA_Logo.png\" alt=\"PUMA Logo\" width=\"200\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _AI model to identify promoter sequences in existing databases_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we check if the dependencies are installed, and if they are not, ask the user if they want to install them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of dependencies\n",
    "dependencies = [\"pandas\", \"scikit-learn\", \"seaborn\", \"plotnine\"] #, \"sbol_utilities\"]\n",
    "\n",
    "# Function to check if a module is installed\n",
    "def is_module_installed(module_name):\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "# Function to install a module\n",
    "def install_module(module_name):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", module_name])\n",
    "\n",
    "# Check each dependency\n",
    "for module in dependencies:\n",
    "    if not is_module_installed(module):\n",
    "        print(f\"The module '{module}' is not installed.\")\n",
    "        answer = input(f\"Do you want to install '{module}'? (yes/no): \")\n",
    "        if answer.lower() == \"yes\":\n",
    "            install_module(module)\n",
    "            print(f\"'{module}' has been installed.\")\n",
    "        else:\n",
    "            print(f\"'{module}' has not been installed.\")\n",
    "    else:\n",
    "        print(f\"The module '{module}' is already installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the packages we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import getpass\n",
    "import requests\n",
    "import re\n",
    "# import sbol3\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing SynBioHub to retrieve the information\n",
    "Here we login into SynBioHub to retrieve the promoters' values. We ask the user for their credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(\n",
    "    'https://synbiohub.org/login',\n",
    "    headers={\n",
    "        'Accept': 'text/plain'\n",
    "    },\n",
    "    data={\n",
    "        'email': input('SynBioHub email: '),\n",
    "        'password' : getpass.getpass('Password: '),\n",
    "        },\n",
    ")\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we search for all the collections in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    'https://synbiohub.org/rootCollections',\n",
    "    headers={\n",
    "        'Accept': 'text/plain',\n",
    "        'X-authorization': response.content\n",
    "        },\n",
    ")\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we look for a specific collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    'https://synbiohub.org/user/carolusvitalis/iGEM_2019_Distribution_Kit_Promoters/iGEM_2019_Distribution_Kit_Promoters_collection/1/sbol',\n",
    "    headers={\n",
    "        'Accept': 'text/plain',\n",
    "        'X-authorization': response.content\n",
    "        },\n",
    ")\n",
    "\n",
    "print(response.status_code)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Search for DNA sequences using regular expression\n",
    "dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', response.content.decode('utf-8'), re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "df = pd.DataFrame(dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SynBioHub (iGEM Collection)\n",
    "This version uses local SBOL files from the 2019 iGEM Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters_2019 = open('./SBOL_Files/iGEM_2019_Promoters_collection.xml').read()\n",
    "\n",
    "rbs_2019 = open('./SBOL_Files/iGEM_2019_RBSs_collection.xml').read()\n",
    "\n",
    "cds_2019 = open('./SBOL_Files/iGEM_2019_CDS_collection.xml').read()\n",
    "\n",
    "t_2019 = open('./SBOL_Files/iGEM_2019_Terminators_collection.xml').read()\n",
    "\n",
    "\n",
    "# Search for DNA sequences using regular expression\n",
    "# Promoters\n",
    "p19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', promoters_2019, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "p19_df = pd.DataFrame(p19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(p19_df))\n",
    "# Print the dataframe\n",
    "#print(p19_df)\n",
    "\n",
    "# RBS\n",
    "rbs19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', rbs_2019, re.DOTALL)\n",
    "rbs19_df = pd.DataFrame(rbs19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "#print(rbs19_df)\n",
    "print(len(rbs19_df))\n",
    "\n",
    "# CDS\n",
    "cds19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', cds_2019, re.DOTALL)\n",
    "cds19_df = pd.DataFrame(cds19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(cds19_df))\n",
    "\n",
    "# Terminators\n",
    "t19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', t_2019, re.DOTALL)\n",
    "t19_df = pd.DataFrame(t19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(t19_df))\n",
    "\n",
    "# why is the first name of the df the name of the collection? \n",
    "# for now, will remove first row so that we have realistic names\n",
    "p19_df = p19_df.drop(p19_df.index[0])\n",
    "\n",
    "# add in promoter label for these seqs\n",
    "p19_df['Element'] = \"Promoter\"\n",
    "\n",
    "rbs19_df = rbs19_df.drop(rbs19_df.index[0])\n",
    "rbs19_df['Element'] = \"RBS\"\n",
    "\n",
    "cds19_df = cds19_df.drop(cds19_df.index[0])\n",
    "cds19_df['Element'] = \"CDS\"\n",
    "\n",
    "t19_df = t19_df.drop(t19_df.index[0])\n",
    "t19_df['Element'] = \"Terminator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in target dataset to apply model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoters_toValidate = open('./SBOL_Files/iGEM_Promoters_collection.xml').read()\n",
    "\n",
    "allPromoters_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', promoters_toValidate, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "allPromoters_df = pd.DataFrame(allPromoters_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "allPromoters_df = allPromoters_df.drop(allPromoters_df.index[0])\n",
    "print(len(allPromoters_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenate promoter and RBS dataframes for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_rbs_cds_ter_df = pd.concat([p19_df, rbs19_df, cds19_df, t19_df], ignore_index=True)\n",
    "print(pro_rbs_cds_ter_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Vectorizing sequences into k-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use CountVectorizer to initialize k-mer splitting \n",
    "# using k=4 for first pass\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(3, 3))\n",
    "\n",
    "# apply the vectorizer to the concat. dataframe\n",
    "X = vectorizer.fit_transform(pro_rbs_cds_ter_df['DNA Sequence']).toarray()\n",
    "y = pro_rbs_cds_ter_df['Element']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Splitting training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters are standard, but we can tweak if needed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Apply to full dataset to classify promoters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = vectorizer.transform(allPromoters_df['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_new = model.predict(X_new)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "allPromoters_df['PredictedType'] = predictions_new\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_df = allPromoters_df[allPromoters_df['PredictedType'] == 'Promoter']\n",
    "print(len(allPromoters_df))\n",
    "print(len(valid_promoters_df))\n",
    "\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_df = allPromoters_df[allPromoters_df['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_df))\n",
    "print(non_promoters_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_nolabels = pro_rbs_cds_ter_df.drop('Element', axis=1)\n",
    "\n",
    "X_old = vectorizer.transform(training_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = model.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "training_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(pro_rbs_cds_ter_df))\n",
    "print(len(valid_promoters_old_df))\n",
    "\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_df = training_nolabels[training_nolabels['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_df))\n",
    "print(non_promoters_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SynBioHub (iGEM Collection) + RegulonDB\n",
    "This version uses both local SBOL files from the 2019 iGEM Distribution, and files from the RegulonDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pro_df = pd.read_csv('./RegulonDB_Files/promoters_Data.csv')\n",
    "ter_df = pd.read_csv('./RegulonDB_Files/terminators_Data.csv')\n",
    "\n",
    "print(pro_df)\n",
    "print(ter_df)\n",
    "\n",
    "pro_df = pro_df.drop(pro_df.index[0])\n",
    "ter_df = ter_df.drop(ter_df.index[0])\n",
    "\n",
    "pro_df['Element'] = \"Promoter\"\n",
    "ter_df['Element'] = \"Terminator\"\n",
    "\n",
    "print(pro_df)\n",
    "print(ter_df)\n",
    "\n",
    "promoters_2019 = open('./SBOL_Files/iGEM_2019_Promoters_collection.xml').read()\n",
    "\n",
    "rbs_2019 = open('./SBOL_Files/iGEM_2019_RBSs_collection.xml').read()\n",
    "\n",
    "cds_2019 = open('./SBOL_Files/iGEM_2019_CDS_collection.xml').read()\n",
    "\n",
    "t_2019 = open('./SBOL_Files/iGEM_2019_Terminators_collection.xml').read()\n",
    "\n",
    "\n",
    "# Search for DNA sequences using regular expression\n",
    "# Promoters\n",
    "p19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', promoters_2019, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "p19_df = pd.DataFrame(p19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(p19_df))\n",
    "# Print the dataframe\n",
    "#print(p19_df)\n",
    "\n",
    "# RBS\n",
    "rbs19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', rbs_2019, re.DOTALL)\n",
    "rbs19_df = pd.DataFrame(rbs19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "#print(rbs19_df)\n",
    "print(len(rbs19_df))\n",
    "\n",
    "# CDS\n",
    "cds19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', cds_2019, re.DOTALL)\n",
    "cds19_df = pd.DataFrame(cds19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(cds19_df))\n",
    "\n",
    "# Terminators\n",
    "t19_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', t_2019, re.DOTALL)\n",
    "t19_df = pd.DataFrame(t19_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(t19_df))\n",
    "\n",
    "# why is the first name of the df the name of the collection? \n",
    "# for now, will remove first row so that we have realistic names\n",
    "p19_df = p19_df.drop(p19_df.index[0])\n",
    "\n",
    "# add in promoter label for these seqs\n",
    "p19_df['Element'] = \"Promoter\"\n",
    "\n",
    "rbs19_df = rbs19_df.drop(rbs19_df.index[0])\n",
    "rbs19_df['Element'] = \"RBS\"\n",
    "\n",
    "cds19_df = cds19_df.drop(cds19_df.index[0])\n",
    "cds19_df['Element'] = \"CDS\"\n",
    "\n",
    "t19_df = t19_df.drop(t19_df.index[0])\n",
    "t19_df['Element'] = \"Terminator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pro_ter_df = pd.concat([pro_df, p19_df, rbs19_df, cds19_df, t19_df, ter_df], ignore_index=True)\n",
    "pro_ter_df = pro_ter_df.dropna(subset=['DNA Sequence'])\n",
    "print(pro_ter_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "\n",
    "output_dir = \"./csv\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "file_path = os.path.join(output_dir, \"pro_ter.csv\")\n",
    "pro_ter_df.to_csv(file_path, index=False)\n",
    "print(f\"Exported DataFrame as CSV: {file_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Ask the user for the size of the k-mers\n",
    "k_mer_size = int(input(\"Enter the size of the k-mers: \"))\n",
    "\n",
    "# Use CountVectorizer to initialize k-mer splitting \n",
    "# Use the user's input as the ngram_range parameter\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(k_mer_size, k_mer_size))\n",
    "\n",
    "# apply the vectorizer to the concat. dataframe\n",
    "X = vectorizer.fit_transform(pro_ter_df['DNA Sequence']).toarray()\n",
    "y = pro_ter_df['Element']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters are standard, but we can tweak if needed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = vectorizer.transform(p19_df['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_new = model.predict(X_new)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "p19_df['PredictedType'] = predictions_new\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_df = p19_df[p19_df['PredictedType'] == 'Promoter']\n",
    "print(len(p19_df))\n",
    "print(len(valid_promoters_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_promoters_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_df = p19_df[p19_df['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_df))\n",
    "print(non_promoters_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_nolabels = pro_ter_df.drop('Element', axis=1)\n",
    "\n",
    "X_old = vectorizer.transform(training_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = model.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "training_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(pro_ter_df))\n",
    "print(len(valid_promoters_old_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_nolabels = pro_df.drop('Element', axis=1)\n",
    "training_nolabels = training_nolabels.dropna(subset=['DNA Sequence'])\n",
    "\n",
    "\n",
    "X_old = vectorizer.transform(training_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = model.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "training_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(pro_df))\n",
    "print(len(valid_promoters_old_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iGEM Repository + RegulonDB\n",
    "This version uses local csv files from the iGEM Repository and the RegulonDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#RegulonDB Files\n",
    "pro_df = pd.read_csv('./RegulonDB_Files/promoters_Data.csv')\n",
    "ter_df = pd.read_csv('./RegulonDB_Files/terminators_Data.csv')\n",
    "gen_df = pd.read_csv('./RegulonDB_Files/genes_Data.csv')\n",
    "\n",
    "print(pro_df)\n",
    "print(ter_df)\n",
    "print(gen_df)\n",
    "\n",
    "# pro_df = pro_df.drop(pro_df.index[0])\n",
    "# ter_df = ter_df.drop(ter_df.index[0])\n",
    "\n",
    "pro_df['Element'] = \"Promoter\"\n",
    "ter_df['Element'] = \"Terminator\"\n",
    "gen_df['Element'] = \"Gene\"\n",
    "\n",
    "print(pro_df)\n",
    "print(ter_df)\n",
    "print(gen_df)\n",
    "\n",
    "#iGEM Repository Files\n",
    "pro_2023 = pd.read_csv('./csv/Promoter_Part_Sequences.csv')\n",
    "rbs_2023 = pd.read_csv('./csv/RBS_Part_Sequences.csv')\n",
    "cds_2023 = pd.read_csv('./csv/CDS_Part_Sequences.csv')\n",
    "ter_2023 = pd.read_csv('./csv/Terminator_Part_Sequences.csv')\n",
    "bkb_2023 = pd.read_csv('./csv/Backbone_Part_Sequences.csv')\n",
    "\n",
    "print(pro_2023)\n",
    "print(rbs_2023)\n",
    "print(cds_2023)\n",
    "print(ter_2023)\n",
    "print(bkb_2023)\n",
    "\n",
    "# pro_2023 = pro_2023.drop(pro_2023.index[0])\n",
    "# rbs_2023 = rbs_2023.drop(rbs_2023.index[0])\n",
    "# cds_2023 = cds_2023.drop(cds_2023.index[0])\n",
    "# ter_2023 = ter_2023.drop(ter_2023.index[0])\n",
    "# bkb_2023 = bkb_2023.drop(bkb_2023.index[0])\n",
    "\n",
    "pro_2023['Element'] = \"Promoter\"\n",
    "rbs_2023['Element'] = \"RBS\"\n",
    "cds_2023['Element'] = \"CDS\"\n",
    "ter_2023['Element'] = \"Terminator\"\n",
    "bkb_2023['Element'] = \"Backbone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parts_df = pd.concat([pro_df, ter_df, pro_2023, rbs_2023, cds_2023, ter_2023, bkb_2023], ignore_index=True)\n",
    "all_parts_df = all_parts_df.dropna(subset=['DNA Sequence'])\n",
    "print(all_parts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import os\n",
    "\n",
    "output_dir = \"./csv\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "file_path = os.path.join(output_dir, \"all_parts.csv\")\n",
    "all_parts_df.to_csv(file_path, index=False)\n",
    "print(f\"Exported DataFrame as CSV: {file_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Ask the user for the size of the k-mers\n",
    "k_mer_size = int(input(\"Enter the size of the k-mers: \"))\n",
    "\n",
    "# Use CountVectorizer to initialize k-mer splitting \n",
    "# Use the user's input as the ngram_range parameter\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(k_mer_size, k_mer_size))\n",
    "\n",
    "# apply the vectorizer to the concat. dataframe\n",
    "X = vectorizer.fit_transform(all_parts_df['DNA Sequence']).toarray()\n",
    "y = all_parts_df['Element']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters are standard, but we can tweak if needed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = vectorizer.transform(pro_2023['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_new = model.predict(X_new)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "pro_2023['PredictedType'] = predictions_new\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_df = pro_2023[pro_2023['PredictedType'] == 'Promoter']\n",
    "print(len(pro_2023))\n",
    "print(len(valid_promoters_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_promoters_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_df = pro_2023[pro_2023['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_df))\n",
    "print(non_promoters_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_nolabels = all_parts_df.drop('Element', axis=1)\n",
    "\n",
    "X_old = vectorizer.transform(training_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = model.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "training_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(all_parts_df))\n",
    "print(len(valid_promoters_old_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_promoters_old_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_old_df))\n",
    "print(non_promoters_old_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igem_pro_file = open('./SBOL_Files/iGEM_Promoters_collection.xml').read()\n",
    "\n",
    "# Search for DNA sequences using regular expression\n",
    "igem_pro_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', igem_pro_file, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "igem_pro_df = pd.DataFrame(igem_pro_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(igem_pro_df))\n",
    "# Print the dataframe\n",
    "#print(igem_pro_df)\n",
    "\n",
    "# why is the first name of the df the name of the collection? \n",
    "# for now, will remove first row so that we have realistic names\n",
    "igem_pro_df = igem_pro_df.drop(igem_pro_df.index[0])\n",
    "\n",
    "# add in promoter label for these seqs\n",
    "igem_pro_df['Element'] = \"Promoter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igem_pro_nolabels = igem_pro_df.drop('Element', axis=1)\n",
    "igem_pro_nolabels = igem_pro_nolabels.dropna(subset=['DNA Sequence'])\n",
    "\n",
    "\n",
    "X_old = vectorizer.transform(igem_pro_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = model.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "igem_pro_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_igem_promoters_df = igem_pro_nolabels[igem_pro_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(igem_pro_df))\n",
    "print(len(valid_igem_promoters_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_igem_promoters_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_igem_df = igem_pro_nolabels[igem_pro_nolabels['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_igem_df))\n",
    "print(non_promoters_igem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"./csv\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "file_path = os.path.join(output_dir, \"igem_non_promoters.csv\")\n",
    "non_promoters_igem_df.to_csv(file_path, index=False)\n",
    "print(f\"Exported DataFrame as CSV: {file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
