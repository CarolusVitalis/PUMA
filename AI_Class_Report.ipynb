{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUMA: Promoter Unraveling through Machine-learning Algorithms\n",
    "<img src=\"https://raw.githubusercontent.com/CarolusVitalis/PUMA/main/Images/PUMA_Logo.png\" alt=\"PUMA Logo\" width=\"200\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _AI model to identify promoter sequences in existing databases_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "Synthetic Biology aims to apply the engineering principles of abstraction, decoupling, and standardization to genetic engineering. In the context of synthetic biology, abstraction refers to the simplification of biological systems into fundamental, manageable components, allowing for a focus on critical interactions and functions while omitting less relevant details. Decoupling, on the other hand, involves the separation of interdependent systems within biology, enabling the independent design, modification, and analysis of each component. Together, these principles facilitate a modular and standardized approach to biological engineering, enhancing understanding, enabling innovative design, and promoting cross-disciplinary collaboration.\n",
    "\n",
    "To improve standardization, synthetic biologists have developed notations and standardized DNA sequences for the different genetic parts, such as promoters, ribosome binding sites (RBSs), and coding sequences (CDSs), among others, which are then collected and deposited in repositories such as the iGEM Part Repository or SynBioHub. Although these repositories offer many different genetic parts and could serve as a good starting point, these parts tend to lack curation, which makes it difficult to identify, classify, and find ideal parts.\n",
    "\n",
    "To overcome this challenge, an AI model was developed to recognize DNA sequences corresponding to Promoters from the iGEM Repository. This will make Synthetic Biology a more accessible field, greatly accelerating the rate of research and novel applications in a wide array of fields, from healthcare to agriculture, and even space colonization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The model was trained with 4127 Promoters and 607 other parts, including RBSs, CDSs, Terminators, and Backbones from the 2023 iGEM Parts Distribution [1] and RegulonDB [2].\n",
    "\n",
    "The iGEM data was scraped using the Part Retriever code [3]. A list of the necessary parts was provided and the code returned a CSV file with the part name and sequence. The parts were manually checked to ensure they were the parts that they claimed to be, this resulted in the deletion of two promoters from the promoters list provided.\n",
    "The RegulonDB data was downloaded in CSV format using the front end and selecting just two fields, name, and sequence. After the files were downloaded, the sequences were standardized to use lowercase annotations.\n",
    "\n",
    "[1] “iGEM Distribution.” Accessed: Feb. 19, 2024. [Online]. Available: https://technology.igem.org/distribution/handbook#h-whats-included-in-the-2023-distribution\n",
    "\n",
    "[2]\t“RegulonDB Browser.” Accessed: Apr. 09, 2024. [Online]. Available: https://regulondb.ccg.unam.mx/\n",
    "\n",
    "[3] “Part_Retriever.” Accessed: Apr. 04, 2024. [Online] Available: https://github.com/CarolusVitalis/PUMA/blob/main/Part_Retriever.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology\n",
    "\n",
    "On the first approach, a Gaussian Naive Bayes machine learning classification was used, achieving a training accuracy of 92.1%, but lacked generalizability to other species than e. coli and misidentified non-promoter genetic parts. Then, a Support Vector Classifier (SVC) model was used, resulting in a training accuracy of 92.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "The SVC model was applied to 2949 entries labeled as Promoters in the iGEM repository and identified 2019 entries as Promoters, 876 as CDS, 22 as RBS, and 32 as Terminators, a significant improvement from the Gaussian Naive Bayes model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies\n",
    "Here, we check if the dependencies are installed, and if they are not, ask the user if they want to install them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of dependencies\n",
    "dependencies = [\"pandas\", \"scikit-learn\", \"seaborn\", \"plotnine\"]\n",
    "\n",
    "# Function to check if a module is installed\n",
    "def is_module_installed(module_name):\n",
    "    try:\n",
    "        __import__(module_name)\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "# Function to install a module\n",
    "def install_module(module_name):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", module_name])\n",
    "\n",
    "# Check each dependency\n",
    "for module in dependencies:\n",
    "    if not is_module_installed(module):\n",
    "        print(f\"The module '{module}' is not installed.\")\n",
    "        answer = input(f\"Do you want to install '{module}'? (yes/no): \")\n",
    "        if answer.lower() == \"yes\":\n",
    "            install_module(module)\n",
    "            print(f\"'{module}' has been installed.\")\n",
    "        else:\n",
    "            print(f\"'{module}' has not been installed.\")\n",
    "    else:\n",
    "        print(f\"The module '{module}' is already installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the packages we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import getpass\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Approach: Gaussian Naïve Bayes\n",
    "This version uses local csv files from the iGEM Repository and the RegulonDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#RegulonDB Files\n",
    "pro_df = pd.read_csv('./RegulonDB_Files/promoters_Data.csv')\n",
    "ter_df = pd.read_csv('./RegulonDB_Files/terminators_Data.csv')\n",
    "gen_df = pd.read_csv('./RegulonDB_Files/genes_Data.csv')\n",
    "\n",
    "print(pro_df)\n",
    "print(ter_df)\n",
    "print(gen_df)\n",
    "\n",
    "# pro_df = pro_df.drop(pro_df.index[0])\n",
    "# ter_df = ter_df.drop(ter_df.index[0])\n",
    "\n",
    "pro_df['Element'] = \"Promoter\"\n",
    "ter_df['Element'] = \"Terminator\"\n",
    "gen_df['Element'] = \"Gene\"\n",
    "\n",
    "print(pro_df)\n",
    "print(ter_df)\n",
    "print(gen_df)\n",
    "\n",
    "#iGEM Repository Files\n",
    "pro_2023 = pd.read_csv('./csv/Promoter_Part_Sequences.csv')\n",
    "rbs_2023 = pd.read_csv('./csv/RBS_Part_Sequences.csv')\n",
    "cds_2023 = pd.read_csv('./csv/CDS_Part_Sequences.csv')\n",
    "ter_2023 = pd.read_csv('./csv/Terminator_Part_Sequences.csv')\n",
    "bkb_2023 = pd.read_csv('./csv/Backbone_Part_Sequences.csv')\n",
    "\n",
    "print(pro_2023)\n",
    "print(rbs_2023)\n",
    "print(cds_2023)\n",
    "print(ter_2023)\n",
    "print(bkb_2023)\n",
    "\n",
    "# pro_2023 = pro_2023.drop(pro_2023.index[0])\n",
    "# rbs_2023 = rbs_2023.drop(rbs_2023.index[0])\n",
    "# cds_2023 = cds_2023.drop(cds_2023.index[0])\n",
    "# ter_2023 = ter_2023.drop(ter_2023.index[0])\n",
    "# bkb_2023 = bkb_2023.drop(bkb_2023.index[0])\n",
    "\n",
    "pro_2023['Element'] = \"Promoter\"\n",
    "rbs_2023['Element'] = \"RBS\"\n",
    "cds_2023['Element'] = \"CDS\"\n",
    "ter_2023['Element'] = \"Terminator\"\n",
    "bkb_2023['Element'] = \"Backbone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parts_df = pd.concat([pro_df, ter_df, pro_2023, rbs_2023, cds_2023, ter_2023, bkb_2023], ignore_index=True)\n",
    "all_parts_df = all_parts_df.dropna(subset=['DNA Sequence'])\n",
    "print(all_parts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "\n",
    "# Ask the user for the size of the k-mers\n",
    "k_mer_size = int(input(\"Enter the size of the k-mers: \"))\n",
    "\n",
    "# Use CountVectorizer to initialize k-mer splitting \n",
    "# Use the user's input as the ngram_range parameter\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(k_mer_size, k_mer_size))\n",
    "\n",
    "# apply the vectorizer to the concat. dataframe\n",
    "X = vectorizer.fit_transform(all_parts_df['DNA Sequence']).toarray()\n",
    "y = all_parts_df['Element']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters are standard, but we can tweak if needed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelGaussian = GaussianNB()\n",
    "modelGaussian.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = modelGaussian.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = vectorizer.transform(pro_2023['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_new = modelGaussian.predict(X_new)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "pro_2023['PredictedType'] = predictions_new\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_df = pro_2023[pro_2023['PredictedType'] == 'Promoter']\n",
    "print(len(pro_2023))\n",
    "print(len(valid_promoters_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_promoters_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_df = pro_2023[pro_2023['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_df))\n",
    "print(non_promoters_df)\n",
    "print(non_promoters_df[['Name', 'PredictedType']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_nolabels = all_parts_df.drop('Element', axis=1)\n",
    "\n",
    "X_old = vectorizer.transform(training_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = modelGaussian.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "training_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(all_parts_df))\n",
    "print(len(valid_promoters_old_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_promoters_old_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_old_df))\n",
    "print(non_promoters_old_df)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": X,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 4,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([modelGaussian, modelSVC]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/CarolusVitalis/PUMA/main/Images/Learning_Curves.png\" alt=\"Learning Curves\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igem_pro_file = open('./SBOL_Files/iGEM_Promoters_collection.xml').read()\n",
    "\n",
    "# Search for DNA sequences using regular expression\n",
    "igem_pro_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', igem_pro_file, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "igem_pro_df = pd.DataFrame(igem_pro_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(igem_pro_df))\n",
    "# Print the dataframe\n",
    "#print(igem_pro_df)\n",
    "\n",
    "# why is the first name of the df the name of the collection? \n",
    "# for now, will remove first row so that we have realistic names\n",
    "igem_pro_df = igem_pro_df.drop(igem_pro_df.index[0])\n",
    "\n",
    "# add in promoter label for these seqs\n",
    "igem_pro_df['Element'] = \"Promoter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igem_pro_nolabels = igem_pro_df.drop('Element', axis=1)\n",
    "igem_pro_nolabels = igem_pro_nolabels.dropna(subset=['DNA Sequence'])\n",
    "\n",
    "\n",
    "X_old = vectorizer.transform(igem_pro_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = model.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "igem_pro_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_igem_promoters_df = igem_pro_nolabels[igem_pro_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(igem_pro_df))\n",
    "print(len(valid_igem_promoters_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_igem_promoters_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_igem_df = igem_pro_nolabels[igem_pro_nolabels['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_igem_df))\n",
    "print(non_promoters_igem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"./csv\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "file_path = os.path.join(output_dir, \"igem_non_promoters.csv\")\n",
    "non_promoters_igem_df.to_csv(file_path, index=False)\n",
    "print(f\"Exported DataFrame as CSV: {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Approach: SVC\n",
    "This version uses local csv files from the iGEM Repository and the RegulonDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#RegulonDB Files\n",
    "pro_df = pd.read_csv('./RegulonDB_Files/promoters_Data.csv')\n",
    "ter_df = pd.read_csv('./RegulonDB_Files/terminators_Data.csv')\n",
    "gen_df = pd.read_csv('./RegulonDB_Files/genes_Data.csv')\n",
    "\n",
    "print(pro_df)\n",
    "print(ter_df)\n",
    "print(gen_df)\n",
    "\n",
    "# pro_df = pro_df.drop(pro_df.index[0])\n",
    "# ter_df = ter_df.drop(ter_df.index[0])\n",
    "\n",
    "pro_df['Element'] = \"Promoter\"\n",
    "ter_df['Element'] = \"Terminator\"\n",
    "gen_df['Element'] = \"Gene\"\n",
    "\n",
    "print(pro_df)\n",
    "print(ter_df)\n",
    "print(gen_df)\n",
    "\n",
    "#iGEM Repository Files\n",
    "pro_2023 = pd.read_csv('./csv/Promoter_Part_Sequences.csv')\n",
    "rbs_2023 = pd.read_csv('./csv/RBS_Part_Sequences.csv')\n",
    "cds_2023 = pd.read_csv('./csv/CDS_Part_Sequences.csv')\n",
    "ter_2023 = pd.read_csv('./csv/Terminator_Part_Sequences.csv')\n",
    "bkb_2023 = pd.read_csv('./csv/Backbone_Part_Sequences.csv')\n",
    "\n",
    "print(pro_2023)\n",
    "print(rbs_2023)\n",
    "print(cds_2023)\n",
    "print(ter_2023)\n",
    "print(bkb_2023)\n",
    "\n",
    "# pro_2023 = pro_2023.drop(pro_2023.index[0])\n",
    "# rbs_2023 = rbs_2023.drop(rbs_2023.index[0])\n",
    "# cds_2023 = cds_2023.drop(cds_2023.index[0])\n",
    "# ter_2023 = ter_2023.drop(ter_2023.index[0])\n",
    "# bkb_2023 = bkb_2023.drop(bkb_2023.index[0])\n",
    "\n",
    "pro_2023['Element'] = \"Promoter\"\n",
    "rbs_2023['Element'] = \"RBS\"\n",
    "cds_2023['Element'] = \"CDS\"\n",
    "ter_2023['Element'] = \"Terminator\"\n",
    "bkb_2023['Element'] = \"Backbone\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parts_df = pd.concat([pro_df, ter_df, pro_2023, rbs_2023, cds_2023, ter_2023, bkb_2023], ignore_index=True)\n",
    "all_parts_df = all_parts_df.dropna(subset=['DNA Sequence'])\n",
    "print(all_parts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import svm\n",
    "\n",
    "# Ask the user for the size of the k-mers\n",
    "k_mer_size = int(input(\"Enter the size of the k-mers: \"))\n",
    "\n",
    "# Use CountVectorizer to initialize k-mer splitting \n",
    "# Use the user's input as the ngram_range parameter\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(k_mer_size, k_mer_size))\n",
    "\n",
    "# apply the vectorizer to the concat. dataframe\n",
    "X = vectorizer.fit_transform(all_parts_df['DNA Sequence']).toarray()\n",
    "y = all_parts_df['Element']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these parameters are standard, but we can tweak if needed\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelSVC = svm.SVC()\n",
    "modelSVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = modelSVC.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = vectorizer.transform(pro_2023['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_new = modelSVC.predict(X_new)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "pro_2023['PredictedType'] = predictions_new\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_df = pro_2023[pro_2023['PredictedType'] == 'Promoter']\n",
    "print(len(pro_2023))\n",
    "print(len(valid_promoters_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_promoters_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_df = pro_2023[pro_2023['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_df))\n",
    "print(non_promoters_df)\n",
    "print(non_promoters_df[['Name', 'PredictedType']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_nolabels = all_parts_df.drop('Element', axis=1)\n",
    "\n",
    "X_old = vectorizer.transform(training_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = modelSVC.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "training_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(all_parts_df))\n",
    "print(len(valid_promoters_old_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_promoters_old_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_old_df = training_nolabels[training_nolabels['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_old_df))\n",
    "print(non_promoters_old_df)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import LearningCurveDisplay, ShuffleSplit\n",
    "import numpy as np\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 6), sharey=True)\n",
    "\n",
    "common_params = {\n",
    "    \"X\": X,\n",
    "    \"y\": y,\n",
    "    \"train_sizes\": np.linspace(0.1, 1.0, 5),\n",
    "    \"cv\": ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
    "    \"score_type\": \"both\",\n",
    "    \"n_jobs\": 4,\n",
    "    \"line_kw\": {\"marker\": \"o\"},\n",
    "    \"std_display_style\": \"fill_between\",\n",
    "    \"score_name\": \"Accuracy\",\n",
    "}\n",
    "\n",
    "for ax_idx, estimator in enumerate([modelGaussian, modelSVC]):\n",
    "    LearningCurveDisplay.from_estimator(estimator, **common_params, ax=ax[ax_idx])\n",
    "    handles, label = ax[ax_idx].get_legend_handles_labels()\n",
    "    ax[ax_idx].legend(handles[:2], [\"Training Score\", \"Test Score\"])\n",
    "    ax[ax_idx].set_title(f\"Learning Curve for {estimator.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igem_pro_file = open('./SBOL_Files/iGEM_Promoters_collection.xml').read()\n",
    "\n",
    "# Search for DNA sequences using regular expression\n",
    "igem_pro_dna_sequences = re.findall(r'<sbol:displayId>(.*?)_sequence</sbol:displayId>.*?<sbol:elements>(.*?)</sbol:elements>', igem_pro_file, re.DOTALL)\n",
    "\n",
    "# Create a pandas dataframe\n",
    "igem_pro_df = pd.DataFrame(igem_pro_dna_sequences, columns=['Name', 'DNA Sequence'])\n",
    "print(len(igem_pro_df))\n",
    "# Print the dataframe\n",
    "#print(igem_pro_df)\n",
    "\n",
    "# why is the first name of the df the name of the collection? \n",
    "# for now, will remove first row so that we have realistic names\n",
    "igem_pro_df = igem_pro_df.drop(igem_pro_df.index[0])\n",
    "\n",
    "# add in promoter label for these seqs\n",
    "igem_pro_df['Element'] = \"Promoter\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "igem_pro_nolabels = igem_pro_df.drop('Element', axis=1)\n",
    "igem_pro_nolabels = igem_pro_nolabels.dropna(subset=['DNA Sequence'])\n",
    "\n",
    "\n",
    "X_old = vectorizer.transform(igem_pro_nolabels['DNA Sequence']).toarray()\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_old = model.predict(X_old)\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "igem_pro_nolabels['PredictedType'] = predictions_old\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_igem_promoters_df = igem_pro_nolabels[igem_pro_nolabels['PredictedType'] == 'Promoter']\n",
    "print(len(igem_pro_df))\n",
    "print(len(valid_igem_promoters_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_igem_promoters_df)\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_igem_df = igem_pro_nolabels[igem_pro_nolabels['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_igem_df))\n",
    "print(non_promoters_igem_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_dir = \"./csv\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "file_path = os.path.join(output_dir, \"igem_non_promoters.csv\")\n",
    "non_promoters_igem_df.to_csv(file_path, index=False)\n",
    "print(f\"Exported DataFrame as CSV: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "all_parts_df\n",
    "\n",
    "\n",
    "# Ask the user for the size of the k-mers\n",
    "k_mer_size = int(input(\"Enter the size of the k-mers: \"))\n",
    "\n",
    "# Use CountVectorizer to initialize k-mer splitting \n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(k_mer_size, k_mer_size))\n",
    "\n",
    "# Setup the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Create a pipeline that incorporates the vectorizer and SVM\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', svm_model)\n",
    "])\n",
    "\n",
    "# Parameters for Grid Search\n",
    "param_grid = {'classifier__C': [0.1, 1, 10, 100], 'classifier__kernel': ['linear', 'rbf']}\n",
    "\n",
    "# Setup nested cross-validation\n",
    "inner_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Inner CV - hyperparameter tuning\n",
    "clf = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=inner_cv)\n",
    "\n",
    "# Outer CV - model evaluation\n",
    "nested_score = cross_val_score(clf, X=all_parts_df['DNA Sequence'], y=all_parts_df['Element'], cv=outer_cv)\n",
    "\n",
    "print(\"Nested CV Accuracy: {:.2f} +/- {:.2f}\".format(nested_score.mean(), nested_score.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "all_parts_df\n",
    "print(all_parts_df.shape[0])\n",
    "print(all_parts_df.columns)\n",
    "# User input for k-mer size\n",
    "k_mer_size = int(input(\"Enter the size of the k-mers: \"))\n",
    "\n",
    "# Setup the CountVectorizer for k-mer splitting\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(k_mer_size, k_mer_size))\n",
    "\n",
    "# Setup the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Create a pipeline with the vectorizer and SVM\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', svm_model)\n",
    "])\n",
    "\n",
    "# Parameters for Grid Search\n",
    "param_grid = {'classifier__C': [.1, 1, 10, 100], 'classifier__kernel': ['linear', 'rbf']}\n",
    "\n",
    "# Setup cross-validation\n",
    "outer_cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Lists to store results\n",
    "best_params = []\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_idx, test_idx in outer_cv.split(all_parts_df):\n",
    "    X_train, X_test = all_parts_df.iloc[train_idx]['DNA Sequence'], all_parts_df.iloc[test_idx]['DNA Sequence']\n",
    "    y_train, y_test = all_parts_df.iloc[train_idx]['Element'], all_parts_df.iloc[test_idx]['Element']\n",
    "    \n",
    "    # Inner CV - hyperparameter tuning\n",
    "    clf = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5)  # Inner cross-validation\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Storing best parameters\n",
    "    best_params.append(clf.best_params_)\n",
    "    \n",
    "    # Evaluate the classifier on the test set using the best found parameters\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# Print the best parameters and accuracy for each outer fold\n",
    "print(\"Best parameters and accuracy for each fold:\")\n",
    "for idx, (params, acc) in enumerate(zip(best_params, accuracy_scores)):\n",
    "    print(f\"Fold {idx+1}: Best Params: {params}, Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Determine the most common best parameters\n",
    "param_counts = Counter([frozenset(param.items()) for param in best_params])\n",
    "most_common_params = param_counts.most_common(1)[0][0]\n",
    "optimal_params = {k: v for k, v in most_common_params}\n",
    "\n",
    "# Print the most common best parameters\n",
    "print(\"Most common best parameters across all folds:\", optimal_params)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming best_params is a list of dictionaries obtained from GridSearchCV\n",
    "from collections import Counter\n",
    "\n",
    "# Calculate the most common best parameters\n",
    "param_counts = Counter(tuple(sorted(d.items())) for d in best_params)\n",
    "most_common_params, _ = param_counts.most_common(1)[0]\n",
    "\n",
    "# Convert to dictionary and remove 'classifier__' prefix from keys\n",
    "optimal_params = {k.split('__')[1]: v for k, v in most_common_params}\n",
    "\n",
    "# Now you can create your final model with these parameters\n",
    "final_model = Pipeline([\n",
    "    ('vectorizer', CountVectorizer(analyzer='char', ngram_range=(k_mer_size, k_mer_size))),\n",
    "    ('classifier', SVC(C=optimal_params['C'], kernel=optimal_params['kernel']))\n",
    "])\n",
    "\n",
    "# Train the final model with the full dataset\n",
    "final_model.fit(all_parts_df['DNA Sequence'], all_parts_df['Element'])\n",
    "\n",
    "\n",
    "# Now the final model is ready to make predictions on new data\n",
    "all_promoters_good = pd.read_csv('./csv/All_Promoters_Part_Sequences.csv')\n",
    "\n",
    "X_new = all_promoters_good['DNA Sequence']\n",
    "\n",
    "# Use the trained model to predict the sequence types\n",
    "predictions_new = final_model.predict(X_new)\n",
    "\n",
    "\n",
    "# Add predictions to the new DataFrame\n",
    "all_promoters_good['PredictedType'] = predictions_new\n",
    "\n",
    "# Filter to identify sequences predicted as promoters\n",
    "valid_promoters_df = all_promoters_good[all_promoters_good['PredictedType'] == 'Promoter']\n",
    "print(len(all_promoters_good))\n",
    "print(len(valid_promoters_df))\n",
    "print(\"Valid Promoters\")\n",
    "print(valid_promoters_df)\n",
    "valid_promoters_df.to_csv(\"./csv/valid_promoters.csv\", index = False)\n",
    "\n",
    "\n",
    "print(\"Non-Promoters\")\n",
    "# Filter to identify sequences predicted as non-promoters\n",
    "non_promoters_df = all_promoters_good[all_promoters_good['PredictedType'] != 'Promoter']\n",
    "print(len(non_promoters_df))\n",
    "print(non_promoters_df)\n",
    "print(non_promoters_df[['Name', 'PredictedType']])\n",
    "non_promoters_df.to_csv(\"./csv/non_promoters.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import learning_curve, KFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "all_parts_df\n",
    "\n",
    "# Set up the CountVectorizer for k-mer splitting\n",
    "k_mer_size = 5  # Set k-mer size\n",
    "vectorizer = CountVectorizer(analyzer='char', ngram_range=(k_mer_size, k_mer_size))\n",
    "\n",
    "# Set up the SVM classifier\n",
    "svm_model = SVC(kernel='linear')\n",
    "\n",
    "# Create a pipeline with the vectorizer and SVM\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', svm_model)\n",
    "])\n",
    "\n",
    "# Prepare training data\n",
    "X, y = all_parts_df['DNA Sequence'], all_parts_df['Element']\n",
    "\n",
    "# Generate learning curve data\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=pipeline,\n",
    "    X=X,\n",
    "    y=y,\n",
    "    train_sizes=np.linspace(.1, 1, 100),\n",
    "    cv=KFold(n_splits=5, shuffle=True, random_state=42),\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Calculate mean and standard deviation for train and test scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "# Plot the learning curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Train score', color='blue', marker='o')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color='blue', alpha=0.15)\n",
    "\n",
    "plt.plot(train_sizes, test_mean, label='Cross-validation score', color='green', marker='o')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color='green', alpha=0.15)\n",
    "\n",
    "plt.title('Learning Curve for SVM Classifier')\n",
    "plt.xlabel('Training Data Size')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/CarolusVitalis/PUMA/main/Images/SVC_Model.png\" alt=\"SVC Model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "The model showed the importance of curating existing databases, especially the iGEM student entries in order to ensure they can be used by scientists without worrying about whether the parts are correctly labeled or not.\n",
    "\n",
    "Tools such as PUMA can help in this regard, ensuring that easily accessible data is also trust worthy. In its current form, PUMA shows impressive results when identifying what is or is not a promoter, but it is not yet able to correctly identify other parts due to the lack of training data for other parts. That opens a door for further development in identification of other parts and even composite sequences."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
